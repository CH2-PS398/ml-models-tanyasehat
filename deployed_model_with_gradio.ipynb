{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio tensorflow_text"
      ],
      "metadata": {
        "id": "09ffbZkBdI88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFMobileBertForQuestionAnswering"
      ],
      "metadata": {
        "id": "Skgeq3pO-bCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Chatbot/dataset/health-care_qa.txt\", 'r', encoding='utf-8') as file:\n",
        "    corpus = file.read()\n",
        "\n",
        "model = TFMobileBertForQuestionAnswering.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/Chatbot/myqamodel/content/myqamodel\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vumichien/mobilebert-uncased-squad-v2\")"
      ],
      "metadata": {
        "id": "EDHQBzJUdHCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_response(message, history):\n",
        "    inputs = tokenizer(message, corpus, max_length=512, truncation=True, return_tensors=\"tf\")\n",
        "\n",
        "    input_ids = inputs.input_ids\n",
        "    attention_mask = inputs.attention_mask\n",
        "    token_type_ids = inputs.token_type_ids\n",
        "\n",
        "    outputs = model([input_ids, attention_mask, token_type_ids])\n",
        "\n",
        "    answer_start_index = int(tf.math.argmax(outputs.start_logits, axis=-1)[0])\n",
        "    answer_end_index = int(tf.math.argmax(outputs.end_logits, axis=-1)[0])\n",
        "\n",
        "    predicted_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 10]\n",
        "    predicted_answer = auto_tokenizer.decode(predicted_tokens, skip_special_tokens=True)\n",
        "\n",
        "    return predicted_answer\n",
        "\n",
        "demo = gr.ChatInterface(random_response)\n",
        "\n",
        "demo.launch(debug=False)"
      ],
      "metadata": {
        "id": "jJ_fXSjnCMC4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}