{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "perWjd4Db1I0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_text\n",
        "\n",
        "import pathlib\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "\n",
        "from transformers import TFMobileBertForQuestionAnswering, MobileBertConfig"
      ],
      "metadata": {
        "id": "UZUKhOcKbiTo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7858abb3-d732-4331-93b9-5c0fd8b3b1e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (0.15.0)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Functions"
      ],
      "metadata": {
        "id": "KAS81_MNb408"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_preprocessor():\n",
        "    preprocessor = hub.load(\"https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-preprocess/versions/3\")\n",
        "\n",
        "    bert_pack_inputs = hub.KerasLayer(\n",
        "        preprocessor.bert_pack_inputs,\n",
        "        arguments=dict(seq_length=512))\n",
        "\n",
        "    tokenizer = hub.KerasLayer(preprocessor.tokenize)\n",
        "\n",
        "    return tokenizer, preprocessor, bert_pack_inputs\n",
        "\n",
        "\n",
        "def define_necessaries():\n",
        "    pretrained_name = \"vumichien/mobilebert-uncased-squad-v2\"\n",
        "    configurator = MobileBertConfig\n",
        "    model_architecture = TFMobileBertForQuestionAnswering\n",
        "\n",
        "    return pretrained_name, configurator, model_architecture\n",
        "\n",
        "\n",
        "def define_dataset(num_examples):\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/Chatbot/dataset/health-care_qa.txt', 'r', encoding='utf-8') as file:\n",
        "        dataset = file.readlines()\n",
        "\n",
        "    questions = []\n",
        "    answers = []\n",
        "\n",
        "    for line in dataset[:num_examples]:\n",
        "        q, a = line.split('\\t')\n",
        "        questions.append(q)\n",
        "        answers.append(a.replace('\\n', ''))\n",
        "\n",
        "    return questions, answers\n",
        "\n",
        "\n",
        "def preprocessing(question, answer):\n",
        "    tokenized_question = tokenizer([question])\n",
        "    tokenized_answer = tokenizer([answer])\n",
        "\n",
        "    packed_inputs = bert_pack_inputs([tokenized_question, tokenized_answer])\n",
        "\n",
        "    input_ids = packed_inputs[\"input_word_ids\"]\n",
        "    attention_mask = packed_inputs[\"input_mask\"]\n",
        "    token_type_ids = packed_inputs[\"input_type_ids\"]\n",
        "\n",
        "    return input_ids, attention_mask, token_type_ids\n",
        "\n",
        "\n",
        "def create_model(pretrained_model_name, configurator, model_arch):\n",
        "    configuration = configurator(\n",
        "        hidden_size=512,\n",
        "        hidden_act='relu',\n",
        "        hidden_dropout_prob=0.2,\n",
        "        attention_probs_dropout_prob=0.2,\n",
        "        max_position_embeddings=512)\n",
        "\n",
        "    model = model_arch.from_pretrained(pretrained_model_name, config=configuration)\n",
        "    model.build()\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "G1YLD0vMbm5S"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execute Functions"
      ],
      "metadata": {
        "id": "IZ3QqPfSb8cP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define preprocessor and its tokenizer\n",
        "tokenizer, preprocessor, bert_pack_inputs = define_preprocessor()\n",
        "\n",
        "# Define the model architecture and configurator\n",
        "pretrained_name, configurator, model_architecture = define_necessaries()\n",
        "\n",
        "# Define \"questions\" and \"answers\" dataset\n",
        "questions, answers = define_dataset(500)\n",
        "\n",
        "# Example of \"Preprocessing Dataset\"\n",
        "ex_input_ids, ex_attention_mask, ex_token_type_ids = preprocessing(questions[0], answers[0])\n",
        "\n",
        "# Define dummy labels\n",
        "start_label = tf.constant([20])\n",
        "end_label = tf.constant([35])\n",
        "\n",
        "# Create model that already been configured\n",
        "model = create_model(pretrained_name, configurator, model_architecture)"
      ],
      "metadata": {
        "id": "u3CMTrqHbopi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6164c79a-a15a-4548-d492-8775b15d3c3c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFMobileBertForQuestionAnswering.\n",
            "\n",
            "All the layers of TFMobileBertForQuestionAnswering were initialized from the model checkpoint at vumichien/mobilebert-uncased-squad-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMobileBertForQuestionAnswering for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_mobile_bert_for_question_answering_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilebert (TFMobileBertMa  multiple                  24581888  \n",
            " inLayer)                                                        \n",
            "                                                                 \n",
            " qa_outputs (Dense)          multiple                  1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24582914 (93.78 MB)\n",
            "Trainable params: 24582914 (93.78 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning and Training"
      ],
      "metadata": {
        "id": "N3sm3slccLKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop(1e-3)\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "history = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch: {epoch + 1}/{EPOCHS}\", end=\" \")\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    for i in range(len(questions)):\n",
        "        with tf.GradientTape() as tape:\n",
        "            input_ids, attention_mask, token_type_ids = preprocessing(questions[i], answers[i])\n",
        "            outputs = model(input_ids, attention_mask, token_type_ids, start_positions=start_label, end_positions=end_label, training=True)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = tf.math.reduce_mean(outputs.loss)\n",
        "            losses.append(round(float(loss), 2))\n",
        "\n",
        "            # Update gradients and apply to the optimizer\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    losses = np.mean(losses)\n",
        "    history.append(losses)\n",
        "\n",
        "    print(f'Loss: {losses}')"
      ],
      "metadata": {
        "id": "TPB1iOL6bq2-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62af38a4-1606-4566-f6f3-611e07a35c2e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/5 Loss: 74133.11196\n",
            "Epoch: 2/5 Loss: nan\n",
            "Epoch: 3/5 Loss: nan\n",
            "Epoch: 4/5 Loss: nan\n",
            "Epoch: 5/5 Loss: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export - Convert - Download Model"
      ],
      "metadata": {
        "id": "0K8OCkztcNo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export Model"
      ],
      "metadata": {
        "id": "_pjj53q5cPw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "export_dir = \"qa_model\"\n",
        "tf.saved_model.save(model, export_dir)"
      ],
      "metadata": {
        "id": "5OktYg98bsdV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert Model into TF Lite Format"
      ],
      "metadata": {
        "id": "MvJWc8wxcRwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "tflite_model_file = pathlib.Path(os.path.join(export_dir, \"qamodel.tflite\"))\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "metadata": {
        "id": "4YZBNv5zbttY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8f11706-f8c8-49e8-fecb-33904c7882ec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22439552"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Converted Model and It's Folder"
      ],
      "metadata": {
        "id": "SSEoD1TScTq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/qa_model.zip /content/qa_model\n",
        "\n",
        "from google.colab import files\n",
        "files.download('qa_model.zip')"
      ],
      "metadata": {
        "id": "_JvYEmoVbvYW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "df1a4234-310c-432c-8dda-213a9cd51171"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/qa_model/ (stored 0%)\n",
            "  adding: content/qa_model/qamodel.tflite (deflated 47%)\n",
            "  adding: content/qa_model/saved_model.pb (deflated 93%)\n",
            "  adding: content/qa_model/assets/ (stored 0%)\n",
            "  adding: content/qa_model/variables/ (stored 0%)\n",
            "  adding: content/qa_model/variables/variables.index (deflated 88%)\n",
            "  adding: content/qa_model/variables/variables.data-00000-of-00001 (deflated 88%)\n",
            "  adding: content/qa_model/fingerprint.pb (stored 0%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_10210ff6-c6ae-47cb-95ce-d93634a0d848\", \"qa_model.zip\", 25955001)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}